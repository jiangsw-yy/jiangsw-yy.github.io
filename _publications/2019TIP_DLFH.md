---
layout: publication
sitemap: false
title: "Discrete Latent Factor Model for Cross-Modal Hashing"
authors: Qing-Yuan Jiang, Wu-Jun Li.
pdf: TIP2019_DLFH
image: TIP2019_DLFH.jpg
display: IEEE Transactions on Image Processing
display_short: TIP
year: 2019
learning2hash: true
cross_modal_retrieval: true
github: https://github.com/jiangqy/DLFH-TIP2019
abstract: "Due to its storage and retrieval efficiency, cross-modal hashing (CMH) has been widely used for cross-modal similarity search in many multimedia applications. According to the training strategy, existing CMH methods can be mainly divided into two categories: relaxation-based continuous methods and discrete methods. In general, the training of relaxation-based continuous methods is faster than discrete methods, but the accuracy of relaxation-based continuous methods is not satisfactory. On the contrary, the accuracy of discrete methods is typically better than relaxation-based continuous methods, but the training of discrete methods is very time-consuming. In this paper, we propose a novel CMH method, called discrete latent factor model based cross-modal hashing (DLFH), for cross modal similarity search. DLFH is a discrete method which can directly learn the binary hash codes for CMH. At the same time, the training of DLFH is efficient. Experiments show that DLFH can achieve significantly better accuracy than existing methods, and the training time of DLFH is comparable to that of relaxation-based continuous methods which are much faster than existing discrete methods."
---
